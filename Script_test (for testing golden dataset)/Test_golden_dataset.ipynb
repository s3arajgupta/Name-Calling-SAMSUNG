{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_golden_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHYWI1K_HoTi"
      },
      "source": [
        "##**A python program for testing the golden dataset**\n",
        "\n",
        "1. It accepts a input.txt file and updates the output.txt file with the prediction values for the same.\n",
        "2. The input.txt file should have three column values i.e serial_no, reference_wav_path and query_wav_path but it doesn't expects these column headers.\n",
        "3. Also, the output.txt file contains two column values i.e serial_no and predicted_value.\n",
        "4. In the test file, update the following variables -\n",
        "      1. path_to_model -> model location\n",
        "      2. path_to_input_txt -> input.txt location\n",
        "      3. path_to_output_txt -> output.txt location\n",
        "\n",
        "5. Finally, run the python script to see the output results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dmKTWylNnyY"
      },
      "source": [
        "###**Importing required libraries/dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJWI76KZLpPe"
      },
      "source": [
        "import os\n",
        "import librosa\n",
        "import skimage.io\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmRSk2anK7pm"
      },
      "source": [
        "**Mounting drive at '/content/drive'.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OzlmSQIOAIL",
        "outputId": "accd8e60-2b6e-4b22-b8a2-40ffa6f1c953"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA6dWEtjNuZU"
      },
      "source": [
        "##**Path to the trained model**\n",
        "\n",
        "* Update the path_to_model variable with the trained model location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkFj3uOiLGXu"
      },
      "source": [
        "Path_to_model = '/content/drive/MyDrive/prism_model/model_congruent'"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GptVtPvCOow_"
      },
      "source": [
        "##**Loading the model from the above given path**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM1Hxz4aN2xk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03a70232-3f65-4b34-f4bc-dbd9ac3580f3"
      },
      "source": [
        "model = keras.models.load_model(Path_to_model, compile=False)\n",
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_61\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_93 (InputLayer)           [(None, 128, 32, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_94 (InputLayer)           [(None, 128, 32, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_60 (Functional)           (None, 16)           24468       input_93[0][0]                   \n",
            "                                                                 input_94[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_30 (Lambda)              (None, 1)            0           model_60[0][0]                   \n",
            "                                                                 model_60[1][0]                   \n",
            "==================================================================================================\n",
            "Total params: 24,468\n",
            "Trainable params: 24,468\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KCHck8wO8NN"
      },
      "source": [
        "###**Path to the Input.txt file and Output.txt file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkAT87McMzRm"
      },
      "source": [
        "Path_to_input_txt =\"/content/textinput.txt\" \n",
        "Path_to_output_txt =\"/content/txtoutput.txt\""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-skk6vTMMEf"
      },
      "source": [
        "def scale_minmax(X, min=0.0, max=1.0):\n",
        "    X_std = (X - X.min()) / (X.max() - X.min())\n",
        "    X_scaled = X_std * (max - min) + min\n",
        "    return X_scaled"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGM2dFWJPTTV"
      },
      "source": [
        "##**Prediction**\n",
        "\n",
        "* Reading serial_no, reference_wav_path and query_wav_path of each row of the input.txt file.\n",
        "* Computing the melspectogram of reference and query wav file.\n",
        "* Preprocessing of the above obtained mel-spectrogram.\n",
        "* Passed them to the model.predict function to get the output.\n",
        "* Stored the serial_no followed by the output value in the output.txt file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxMBZxzGDvda",
        "outputId": "2fe8ddae-7a5d-4e75-9a7d-abf7d8986a9f"
      },
      "source": [
        "f=open(Path_to_input_txt,\"r\")\n",
        "for line in f:\n",
        "    words=line.split()\n",
        "    if words:\n",
        "        serial_no = words[0];\n",
        "        reference_path = words[1];\n",
        "        query_path = words[2];\n",
        "\n",
        "\n",
        "        # take reference wav as input and found its mel-spectogram\n",
        "        y1,sr1 = librosa.load(reference_path, duration=1,sr=16000)\n",
        "        N = 16000-len(y1)\n",
        "        y1=np.pad(y1, (0, N), 'constant')\n",
        "        mel1 = librosa.feature.melspectrogram(y=y1,sr=sr1)\n",
        "        ref_img = scale_minmax(mel1, 0, 255).astype(np.uint8)\n",
        "        ref_img_array = np.expand_dims(ref_img, axis=-1)\n",
        "        ref_img_array = np.expand_dims(ref_img_array, axis=0)\n",
        "        ref_img_array = ref_img_array.astype('float32')\n",
        "        ref_img_array /= 255\n",
        "\n",
        "        # take query wav as input and found its mel-spectogram\n",
        "        y2,sr2 = librosa.load(query_path, duration=1,sr=16000)\n",
        "        N = 16000-len(y2)\n",
        "        y2=np.pad(y2, (0, N), 'constant')\n",
        "        mel2 = librosa.feature.melspectrogram(y=y2,sr=sr2)\n",
        "        que_img = scale_minmax(mel2, 0, 255).astype(np.uint8)\n",
        "        que_img_array = np.expand_dims(que_img, axis=-1)\n",
        "        que_img_array = np.expand_dims(que_img_array, axis=0)\n",
        "        que_img_array = que_img_array.astype('float32')\n",
        "        que_img_array /= 255\n",
        "\n",
        "        #predicting the distance between reference wav file and query wav file\n",
        "        temp = model.predict([ref_img_array, que_img_array])\n",
        "        print(temp)\n",
        "        temp=(int)(temp.ravel() < 0.5)\n",
        "\n",
        "\n",
        "        f2 = open(Path_to_output_txt,\"a\")\n",
        "        L = str(serial_no)+ \"\\t\"  + str(temp) + \"\\n\"\n",
        "        f2.write(L)\n",
        "        f2.close()\n",
        "        \n",
        "f.close()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.3729024]]\n",
            "[[0.58687615]]\n",
            "[[1.0829484]]\n",
            "[[0.40849155]]\n",
            "[[0.85522866]]\n",
            "[[0.31289312]]\n",
            "[[0.21277499]]\n",
            "[[1.04822]]\n",
            "[[0.30858466]]\n",
            "[[0.37659955]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPquSFu6M_oW"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}